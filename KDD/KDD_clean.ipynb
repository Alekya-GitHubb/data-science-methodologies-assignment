{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle\n",
    "!mkdir ~/.kaggle\n",
    "from google.colab import files\n",
    "files.upload()  # upload your kaggle.json here\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "!kaggle datasets download -d olistbr/brazilian-ecommerce -p data --unzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "files = os.listdir(\"data\")\n",
    "files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "path = \"data\"\n",
    "\n",
    "orders = pd.read_csv(f\"{path}/olist_orders_dataset.csv\")\n",
    "customers = pd.read_csv(f\"{path}/olist_customers_dataset.csv\")\n",
    "reviews = pd.read_csv(f\"{path}/olist_order_reviews_dataset.csv\")\n",
    "items = pd.read_csv(f\"{path}/olist_order_items_dataset.csv\")\n",
    "payments = pd.read_csv(f\"{path}/olist_order_payments_dataset.csv\")\n",
    "products = pd.read_csv(f\"{path}/olist_products_dataset.csv\")\n",
    "sellers = pd.read_csv(f\"{path}/olist_sellers_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.head(), customers.head(), reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews[\"target\"] = (reviews[\"review_score\"] <= 3).astype(int)\n",
    "reviews[\"target\"].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders[\"customer_id\"].nunique(), customers[\"customer_id\"].nunique()\n",
    "reviews[\"order_id\"].nunique(), orders[\"order_id\"].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = orders[orders[\"order_status\"] != \"canceled\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge orders + customers\n",
    "df = orders.merge(customers, on=\"customer_id\", how=\"left\")\n",
    "\n",
    "# Add reviews\n",
    "df = df.merge(reviews[[\"order_id\", \"target\"]], on=\"order_id\", how=\"inner\")\n",
    "\n",
    "# Add payments\n",
    "df = df.merge(payments.groupby(\"order_id\")\n",
    "              .agg({\"payment_sequential\":\"max\",\n",
    "                    \"payment_type\":\"first\",\n",
    "                    \"payment_installments\":\"max\",\n",
    "                    \"payment_value\":\"sum\"})\n",
    "              .reset_index(),\n",
    "              on=\"order_id\", how=\"left\")\n",
    "\n",
    "# Add items (total price, freight, item count)\n",
    "items_agg = items.groupby(\"order_id\").agg({\n",
    "    \"price\":\"sum\",\n",
    "    \"freight_value\":\"sum\",\n",
    "    \"order_item_id\":\"count\"\n",
    "}).rename(columns={\"order_item_id\":\"num_items\"}).reset_index()\n",
    "\n",
    "df = df.merge(items_agg, on=\"order_id\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = [c for c in df.columns if \"date\" in c or \"timestamp\" in c]\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"target\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "df.shape\n",
    "df[\"target\"].value_counts(normalize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delivery time (days)\n",
    "df[\"delivery_time\"] = (df[\"order_delivered_customer_date\"] - df[\"order_purchase_timestamp\"]).dt.days\n",
    "\n",
    "# Estimated delivery time\n",
    "df[\"estimated_delivery_time\"] = (df[\"order_estimated_delivery_date\"] - df[\"order_purchase_timestamp\"]).dt.days\n",
    "\n",
    "# Delay (delivery - estimate)\n",
    "df[\"delay\"] = df[\"delivery_time\"] - df[\"estimated_delivery_time\"]\n",
    "\n",
    "# Late delivery flag\n",
    "df[\"late_delivery\"] = (df[\"delay\"] > 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"purchase_month\"] = df[\"order_purchase_timestamp\"].dt.month\n",
    "df[\"purchase_day\"] = df[\"order_purchase_timestamp\"].dt.day\n",
    "df[\"purchase_weekday\"] = df[\"order_purchase_timestamp\"].dt.weekday\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"customer_state\"] = df[\"customer_state\"].astype(\"category\")\n",
    "df[\"customer_city\"] = df[\"customer_city\"].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"delivery_time\", \"estimated_delivery_time\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"price\", \"freight_value\", \"num_items\",\n",
    "    \"payment_installments\", \"payment_value\",\n",
    "    \"delivery_time\", \"estimated_delivery_time\",\n",
    "    \"delay\", \"late_delivery\",\n",
    "    \"purchase_month\", \"purchase_day\", \"purchase_weekday\",\n",
    "    \"customer_city\", \"customer_state\"\n",
    "]\n",
    "\n",
    "target = \"target\"\n",
    "\n",
    "df_model = df[features + [target]].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"price\", \"freight_value\", \"num_items\",\n",
    "    \"payment_installments\", \"payment_value\",\n",
    "    \"delivery_time\", \"estimated_delivery_time\",\n",
    "    \"delay\",\n",
    "    \"purchase_month\", \"purchase_day\", \"purchase_weekday\"\n",
    "]\n",
    "\n",
    "cat_cols = [\"customer_city\", \"customer_state\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_model[num_cols + cat_cols]\n",
    "y = df_model[target]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_valid), len(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", xgb)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "y_proba = model.predict_proba(X_valid)[:,1]\n",
    "\n",
    "print(\"AUC:\", roc_auc_score(y_valid, y_proba))\n",
    "print(classification_report(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_proba = model.predict_proba(X_valid)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_valid, y_proba)\n",
    "\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1], \"--\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "\n",
    "print(\"AUC:\", auc(fpr, tpr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_valid, y_proba)\n",
    "ap = average_precision_score(y_valid, y_proba)\n",
    "\n",
    "plt.plot(recall, precision)\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Average Precision Score:\", ap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "cm = confusion_matrix(y_valid, y_pred)\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lah /content/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reviews = pd.read_csv(\"/content/data/olist_order_reviews_dataset.csv\")\n",
    "reviews.head()\n",
    "reviews.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = reviews.copy()\n",
    "\n",
    "# Create binary target column: 1 = negative review, 0 = positive review\n",
    "final_df[\"target\"] = (final_df[\"review_score\"] <= 3).astype(int)\n",
    "\n",
    "final_df[[\"review_score\", \"target\"]].head()\n",
    "final_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"/content/data/final_preprocessed_reviews.csv\", index=False)\n",
    "print(\"✅ File saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh /content/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/content/data/final_preprocessed_reviews.csv\")\n",
    "\n",
    "# Sample 15% of dataset randomly for SHAP experiment\n",
    "df_sample = df.sample(frac=0.15, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(df_sample.shape)\n",
    "df_sample.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_sample[\"review_comment_message\"].fillna(\"\")\n",
    "y = df_sample[\"target\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=5000, stop_words=\"english\")),\n",
    "    (\"clf\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ Model trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def predict_proba_text(x):\n",
    "    # Convert numpy array → DataFrame with correct column name\n",
    "    if isinstance(x, np.ndarray):\n",
    "        x = pd.DataFrame(x, columns=[\"review_comment_message\"])\n",
    "    return pipeline.predict_proba(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train))\n",
    "print(type(X_val))\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Fix target column name based on your dataset\n",
    "target_col = \"review_score\"   # change if your target name is different\n",
    "\n",
    "X = final_df.drop(columns=[target_col])\n",
    "y = final_df[target_col]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"✅ Re-split done. Shapes:\")\n",
    "print(X_train.shape, X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_cols = [\"review_comment_message\", \"review_comment_title\", \"review_text\", \"text\"]\n",
    "\n",
    "text_col = None\n",
    "for c in possible_cols:\n",
    "    if c in X_train.columns:\n",
    "        text_col = c\n",
    "        break\n",
    "\n",
    "if text_col is None:\n",
    "    raise ValueError(\"❌ Could not find text column — check final_df.columns()\")\n",
    "\n",
    "print(\"✅ Using text column:\", text_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = X_train[[text_col]]   # ✅ double brackets keep DataFrame\n",
    "X_val_text   = X_val[[text_col]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_train_text))\n",
    "print(type(X_val_text))\n",
    "print(X_train_text.head())\n",
    "print(X_train_text.shape, X_val_text.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "# SHAP sampling\n",
    "sample_size = int(len(X_val_text) * 0.10)  # 10% text for SHAP\n",
    "idx = np.random.choice(len(X_val_text), sample_size, replace=False)\n",
    "\n",
    "X_shap = X_val_text.iloc[idx]\n",
    "\n",
    "# background sample\n",
    "X_bg = X_train_text.sample(300, random_state=42)  # small background set\n",
    "\n",
    "# SHAP kernel explainer\n",
    "explainer = shap.KernelExplainer(predict_proba_text, X_bg)\n",
    "shap_values = explainer.shap_values(X_shap, nsamples=100)\n",
    "\n",
    "print(\"✅ SHAP values computed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only class 1 SHAP values and remove extra bias column\n",
    "sv = shap_values[1][:, :-1]\n",
    "\n",
    "shap.summary_plot(sv, X_shap, feature_names=[text_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force plot for one instance\n",
    "i = 0  # first row since only one feature\n",
    "\n",
    "shap.force_plot(\n",
    "    explainer.expected_value[1],   # for positive class\n",
    "    sv[i],                         # SHAP values for that row\n",
    "    X_shap.iloc[i],                # original text\n",
    "    matplotlib=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save pipeline and model\n",
    "joblib.dump(pipeline, \"final_review_model.pkl\")\n",
    "print(\"✅ Model saved as final_review_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "import joblib\n",
    "loaded_model = joblib.load(\"final_review_model.pkl\")\n",
    "\n",
    "# Inference function\n",
    "def predict_sentiment(text):\n",
    "    return loaded_model.predict([text])[0]\n",
    "\n",
    "# Test on sample reviews\n",
    "test_reviews = [\n",
    "    \"The product was excellent and delivery was fast\",\n",
    "    \"Terrible quality, I want a refund!\",\n",
    "    \"Average experience, nothing special\"\n",
    "]\n",
    "\n",
    "for review in test_reviews:\n",
    "    print(f\"Review: {review}\")\n",
    "    print(\"Prediction:\", \"Positive ✅\" if predict_sentiment(review)==1 else \"Negative ❌\")\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save(\"shap_values.npy\", shap_values)\n",
    "print(\"✅ SHAP values saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Replace NaN values with empty string\n",
    "X_val_text = X_val_text.fillna(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# ✅ Predict using pipeline on clean text\n",
    "y_pred = pipeline.predict(X_val_text[\"review_comment_message\"])\n",
    "\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(pipeline, \"kdd_review_classifier.pkl\")\n",
    "print(\"✅ Model saved for deployment!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reviews = [\n",
    "    \"Produto chegou antes do prazo e tudo certo\", # positive\n",
    "    \"Péssima qualidade, chegou quebrado\",        # negative\n",
    "]\n",
    "\n",
    "test_df = pd.DataFrame(test_reviews, columns=[\"review_comment_message\"])\n",
    "preds = pipeline.predict(test_df)\n",
    "\n",
    "for txt, pred in zip(test_reviews, preds):\n",
    "    print(f\"Review: {txt} → Prediction: {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(pipeline, \"kdd_review_model.pkl\")\n",
    "print(\"✅ Model saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = joblib.load(\"kdd_review_model.pkl\")\n",
    "model_loaded.predict(pd.DataFrame([\"Produto ótimo, entrega rápida\"], columns=[\"review_comment_message\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_reviews = [\n",
    "    \"Produto excelente, recomendo\",\n",
    "    \"Horrível, veio quebrado\",\n",
    "    \"Entrega rápida, mas qualidade ruim\",\n",
    "    \"Muito bom, chegou antes do prazo\"\n",
    "]\n",
    "\n",
    "df_test = pd.DataFrame(sample_reviews, columns=[\"review_comment_message\"])\n",
    "y_pred = pipeline.predict(df_test)\n",
    "\n",
    "for txt, pred in zip(sample_reviews, y_pred):\n",
    "    print(f\"{txt} => {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Final inference function for deployment simulation\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load saved pipeline\n",
    "pipeline = joblib.load(\"kdd_review_model.pkl\")\n",
    "\n",
    "def predict_review(text):\n",
    "    df = pd.DataFrame([text], columns=[\"review_comment_message\"])\n",
    "    pred = pipeline.predict(df)[0]\n",
    "    return \"Positive\" if pred == 1 else \"Negative\"\n",
    "\n",
    "# Test on examples\n",
    "samples = [\n",
    "    \"Produto excelente, recomendo!\",\n",
    "    \"Muito ruim, chegou quebrado e atrasado\",\n",
    "    \"Entrega rápida, mas qualidade baixa\",\n",
    "    \"Ótimo, compraria novamente!\"\n",
    "]\n",
    "\n",
    "for s in samples:\n",
    "    print(f\"Review: {s} → Prediction: {predict_review(s)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pipeline and SHAP values already done earlier\n",
    "print(\"✅ Model + explainability artifacts ready for deployment\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"processed_reviews_kdd.csv\", index=False)\n",
    "print(\"✅ Processed data exported\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
